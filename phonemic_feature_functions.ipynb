{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483082a1",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123ad4a",
   "metadata": {},
   "source": [
    "#### Syllable Count (adjusts NLTK tokenizer for the *magic \"e\"* rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSP = SyllableTokenizer()\n",
    "def magic_e(word):\n",
    "    \n",
    "    result = SSP.tokenize(word)\n",
    "    syll_count = len(result)\n",
    "    \n",
    "    if syll_count == 1:\n",
    "        return syll_count\n",
    "    \n",
    "    if re.search('e$', result[len(result) - 1]):\n",
    "        modified = ''.join([result[i] for i in [len(result) - 2, len(result) - 1]])\n",
    "        result[len(result) - 2] = modified\n",
    "        del result[len(result) - 1]\n",
    "        syll_count = len(result)\n",
    "        \n",
    "    return syll_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c12644",
   "metadata": {},
   "source": [
    "#### POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_POS(row):\n",
    "    \n",
    "    retList = []\n",
    "    \n",
    "    for tag in nltk.pos_tag(row):\n",
    "        retList.append(tag[1])\n",
    "    \n",
    "    return retList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4c6b3",
   "metadata": {},
   "source": [
    "#### Get IPA translations (using provided translations from https://github.com/open-dict-data/ipa-dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('phoneticDictionary.csv')\n",
    "df = pd.DataFrame(list(zip(df['word'], df['phon'])), columns=['word', 'ipa'])\n",
    "\n",
    "def ipa(section):\n",
    "    total_words = 0\n",
    "    ipa_word = list(df['word'])\n",
    "    ipa_notation = list(df['ipa'])\n",
    "    ipa_dict = dict(zip(ipa_word, ipa_notation))\n",
    "    new_sent = []\n",
    "    for row in section.text:\n",
    "        sent = []\n",
    "        words = 0\n",
    "        for word in row:\n",
    "            total_words += 1\n",
    "            words += 1\n",
    "            if word in ipa_dict.keys():\n",
    "                this_word = ipa_dict[word].replace(\"ˈ\", \"\")\n",
    "                this_word = this_word.replace(\"ˌ\", \"\")\n",
    "                sent.append(this_word)\n",
    "            elif word in punctuation:\n",
    "                sent.append(word)\n",
    "            else:\n",
    "                sent.append(' ')\n",
    "        new_sent.append(sent)\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cd32b",
   "metadata": {},
   "source": [
    "## Letter-Name Alphabetic Stage Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034811e",
   "metadata": {},
   "source": [
    "#### Check for words with consonant-vowel-consonant short vowel pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_CVC_short(dataset):\n",
    "    \n",
    "    CVC_short = []\n",
    "    for row in tqdm(dataset['ipa']):\n",
    "        cvc = 0\n",
    "        total_words = 0\n",
    "        for word in row:\n",
    "            total_words += 1\n",
    "            if re.search('^[btkzɹsjmfgndɫwpθvhʃð][btkzɹsjmfgndɫwpθvhʃðʒŋ]*[ɪɑæəʊɛ][btkzɹsjmfgndɫwpθvhʃðʒŋ]*[btkzɹsjmfgndɫwpθvhʃðʒŋ]$', word):\n",
    "                cvc += 1\n",
    "        \n",
    "        CVC_short.append(cvc / total_words)\n",
    "    \n",
    "    return CVC_short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97afd08",
   "metadata": {},
   "source": [
    "## Within-Word Pattern Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6fcf5",
   "metadata": {},
   "source": [
    "#### Check for basic inflectionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_basic_inflectional(dataset):\n",
    "    \n",
    "    verb_tags = ['VBD', 'VBG', 'VBN', 'VBZ']\n",
    "    text_POS = list(zip(dataset['text'], dataset['POS']))\n",
    "    inflectional = []\n",
    "    \n",
    "    for item in tqdm(text_POS):\n",
    "        total_words = 0\n",
    "        inf_end = 0\n",
    "        i = 0\n",
    "        for word in item[0]:\n",
    "            total_words += 1\n",
    "            if item[1][i] in verb_tags:\n",
    "                if re.search('es$', word):\n",
    "                    inf_end += 1\n",
    "                if re.search('s$', word):\n",
    "                    inf_end += 1\n",
    "            i += 1\n",
    "            \n",
    "        inflectional.append(inf_end / total_words)\n",
    "    \n",
    "    return inflectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6fcb4",
   "metadata": {},
   "source": [
    "#### Check for complex consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_complex_cons(dataset):\n",
    "    \n",
    "    _complex = []\n",
    "    text_ipa = list(zip(dataset['text'], dataset['ipa']))\n",
    "    \n",
    "    for item in tqdm(text_ipa):\n",
    "        total_words = 0\n",
    "        com_cons = 0\n",
    "        i = 0\n",
    "        for word in item[0]:\n",
    "            total_words += 1\n",
    "            sylls = magic_e(word)\n",
    "            if sylls == 1:\n",
    "                if re.search('g', item[0][i]):\n",
    "                    if not re.search('g', item[1][i]):\n",
    "                        com_cons += 1\n",
    "                if re.search('^w', item[0][i]):\n",
    "                    if not re.search('w', item[1][i]):\n",
    "                        com_cons += 1\n",
    "                if re.search('c', item[0][i]):\n",
    "                    if not re.search('k', item[1][i]):\n",
    "                        com_cons += 1\n",
    "                if re.search('k', item[0][i]):\n",
    "                    if not re.search('k', item[1][i]):\n",
    "                        com_cons += 1\n",
    "                if re.search('dʒ$', item[1][i]):\n",
    "                    com_cons += 1\n",
    "                if re.search('se$', item[0][i]):\n",
    "                    if re.search('z$', item[1][i]):\n",
    "                        com_cons += 1\n",
    "                if re.search('b$', item[0][i]):\n",
    "                    if not re.search('b', item[1][i]):\n",
    "                        com_cons += 1\n",
    "                if re.search('ce$', item[0][i]):\n",
    "                    if re.search('s$', item[1][i]):\n",
    "                        com_cons += 1\n",
    "                if re.search('[btkzrsjmfndlwpvhg]ch$', item[0][i]):\n",
    "                    com_cons += 1\n",
    "                if re.search('[btkzrsjmfndlwpvhg]ge$', item[0][i]):\n",
    "                    com_cons += 1\n",
    "                    \n",
    "            i += 1\n",
    "            \n",
    "        _complex.append(com_cons / total_words)\n",
    "        \n",
    "    return _complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e610a8a",
   "metadata": {},
   "source": [
    "## Syllables & Affixes Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e47db",
   "metadata": {},
   "source": [
    "#### Check type of syllable juncture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VV_word(row):\n",
    "    \n",
    "    DIPHTHONGS = ['aɪ', 'eɪ', 'ɪə', 'ɔɪ', 'aʊ', 'oʊ', 'ʊə', 'eə']\n",
    "    \n",
    "    vv = False\n",
    "    vv_dict = {}\n",
    "    for word in row:\n",
    "        if re.search('[ɪɑæəʊɛiuɔaoe][ɪɑæəʊɛiuɔaoe][ɪɑæəʊɛiuɔaoe]', word):\n",
    "            vv = True\n",
    "        elif re.search('[ɪɑæəʊɛiuɔaoe][ɫɝ]', word):\n",
    "            vv = True\n",
    "        elif re.search('[ɪɑæəʊɛiuɔaoe][ɪɑæəʊɛiuɔaoe]', word):\n",
    "            result = re.findall('[ɪɑæəʊɛiuɔaoe][ɪɑæəʊɛiuɔaoe]', word)\n",
    "            for res in result:\n",
    "                if res not in DIPHTHONGS:\n",
    "                    vv = True\n",
    "        vv_dict[word] = vv\n",
    "        \n",
    "    return vv_dict\n",
    "    \n",
    "    \n",
    "def VCCV_doublet_word(row):\n",
    "    \n",
    "    vccv_doublet_dict = {}\n",
    "    vccv = False\n",
    "    for word in row:\n",
    "        sylls = magic_e(word)\n",
    "        if sylls < 2:\n",
    "            break\n",
    "        if re.search('[aeiou][btkzrsjmfndlwpvhg][btkzrsjmfndlwpvhg][aeiou]', word):\n",
    "            result = magic_e_result(word)\n",
    "            if result[0][-1] in CONSONANTS_TEXT:\n",
    "                con = result[0][-1]\n",
    "                if con == result[1][0]:\n",
    "                    vccv = True\n",
    "        vccv_doublet_dict[word] = vccv\n",
    "        \n",
    "    return vccv_doublet_dict\n",
    "    \n",
    "\n",
    "def VCCV_word(row):\n",
    "\n",
    "    vccv_dict = {}\n",
    "    vccv = False\n",
    "    for word in row:\n",
    "        sylls = magic_e(word)\n",
    "        if sylls < 2:\n",
    "            break\n",
    "        if re.search('[aeiou][btkzrsjmfndlwpvhg][btkzrsjmfndlwpvhg][aeiou]', word):\n",
    "            result = magic_e_result(word)\n",
    "            if result[0][-1] in CONSONANTS_TEXT:\n",
    "                con = result[0][-1]\n",
    "                if con != result[1][0]:\n",
    "                    vccv = True\n",
    "        vccv_dict[word] = vccv\n",
    "        \n",
    "    return vccv_dict\n",
    "\n",
    "\n",
    "def VCCCV_word(row):\n",
    "    \n",
    "    vcccv_list = {}\n",
    "    vcccv = False\n",
    "    for word in row:\n",
    "        sylls = magic_e(word)\n",
    "        if sylls == 2:\n",
    "            if re.search('[aeiou][btkzrsjmfndlwpvhg][btkzrsjmfndlwpvhg][btkzrsjmfndlwpvhg][aeiou]', word):\n",
    "                vcccv = True\n",
    "                    \n",
    "        vcccv_list[word] = vcccv\n",
    "            \n",
    "    return vcccv_list\n",
    "\n",
    "\n",
    "def VVCV_word(row):\n",
    "    \n",
    "    vvcv_list = {}\n",
    "    vvcv = False\n",
    "    for word in row:\n",
    "        sylls = magic_e(word)\n",
    "        if sylls == 2:\n",
    "            if re.search('[aeiou][aeiou][btkzrsjmfndlwpvhg][aeiou]', word):\n",
    "                vvcv = True\n",
    "                    \n",
    "        vvcv_list[word] = vvcv\n",
    "            \n",
    "    return vvcv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c27867",
   "metadata": {},
   "source": [
    "## Derivational Relations Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384edf2",
   "metadata": {},
   "source": [
    "#### Check for advanced suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23175531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adv_suffix_word(row):\n",
    "    \n",
    "    adjs_nouns = ['JJR', 'JJS', 'JJ', 'NN', 'NNP', 'NNS']\n",
    "    verbs = ['VB', 'VBD', 'VBG', 'VBN', 'VBZ', 'VBP']\n",
    "    \n",
    "    adj_n_suffix = ['ɛɹi$', 'ɔɹi$', 'ənsi$', 'əns$', 'ʒən', 'ʒən', 'ʃən', 'əbəɫ$', 'əbɫi$']\n",
    "    v_suffix = ['aɪz', 'ɪfaɪ', 'əfaɪ']\n",
    "    \n",
    "    pos = get_POS(row)\n",
    "    ipa = []\n",
    "    ret_dict = {}\n",
    "    for word in row:\n",
    "        ipa.append(ipa_word(word))\n",
    "        ret_dict[ipa_word(word)] = word\n",
    "    ipa_text = list(zip(ipa, row, pos))\n",
    "    i = 0\n",
    "    retWords = []\n",
    "    for word in ipa:\n",
    "        if len(word) > 0:\n",
    "            if magic_e(row[i]) > 1:\n",
    "                if pos[i] in adjs_nouns:\n",
    "                    for suf in adj_n_suffix:\n",
    "                        if re.search(suf, word):\n",
    "                            if ret_dict[word] not in retWords:\n",
    "                                retWords.append(ret_dict[word])\n",
    "                if pos[i] in verbs:\n",
    "                    for suf in v_suffix:\n",
    "                        if re.search(suf, word):\n",
    "                            if ret_dict[word] not in retWords:\n",
    "                                retWords.append(ret_dict[word])\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    return retWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7eff7e",
   "metadata": {},
   "source": [
    "#### Check for assimilated prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_assimilated_row(row):\n",
    "    assimilated = 0\n",
    "    total_words = 0\n",
    "    retWords = []\n",
    "    for word in row:\n",
    "        total_words += 1\n",
    "        if len(magic_e_result(word)) > 1:\n",
    "            if re.search('^ill', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^imm[aeiou]', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^imp', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^irr[aeiou]', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^suff', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^supp', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^succ', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^surr', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^coll', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^corr', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^att', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^aff', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^agg', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^all', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^ann', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^app', word):\n",
    "                if not re.search('apples', word):\n",
    "                    assimilated += 1\n",
    "                    if word not in retWords:\n",
    "                        retWords.append(word)\n",
    "            if re.search('^ass', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^arr', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^diff', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^eff', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^opp', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^off', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "            if re.search('^occ', word):\n",
    "                assimilated += 1\n",
    "                if word not in retWords:\n",
    "                    retWords.append(word)\n",
    "                    \n",
    "    return retWords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
